Facial Expression & Affective Computing

This project uses Convolutional Neural Networks (CNNs) to detect facial expressions and compute valence (positivity/negativity) and arousal (intensity) from images. Multiple CNN architectures like VGG, ResNet, and MobileNet are compared for performance.

Features

Recognizes basic emotions: happy, sad, angry, surprise, fear, disgust, neutral

Computes valence and arousal for nuanced affective analysis

Evaluates different CNN models for accuracy and performance

Dataset

Uses annotated facial image datasets with expression, valence, and arousal labels.

Usage

Can be applied in research, human-computer interaction, emotion analysis, and affective computing applications.
